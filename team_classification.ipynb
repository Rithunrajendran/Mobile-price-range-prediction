{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rithunrajendran/Mobile-price-range-prediction/blob/main/team_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Mobile Price Range Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    -Team\n",
        "##### **Team Member 1** - Rithun Rajendran M.K\n",
        "##### **Team Member 2** - Affan Ahmad Abdul Wahid\n",
        "##### **Team Member 3** - Prajwal Bharadwaj\n",
        "##### **Team Member 4** - Shreyash Kumar\n",
        "##### **Team Member 5** -Md Ashique Ali"
      ],
      "metadata": {
        "id": "bMxEQyrkWDVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mobile Price Range  Prediction is done by group of 5 members.All the members have equal contribution in this project.In this project we first got the data_mobile_price_range.csv file , as we downloaded the csv files from the almabetter dashboard we encoded the file in the colab notebook by mounting the drive.We named  the csv files as Mobile_df  and included the csv file in it.Then we checked the missing/null values in  the dataset and we found that \n",
        "there are 2000 rows and 21 columns.There seems to be no null values in it. It has integer and float as data types.Then we done certain visualization techniques on the dataset to find the relationship between the features. After that we have done the feature engineering and the data preprocessing part where we handled the outliers  and then we have checked the  categorical encoding,feature manupulation and feature selection,checked multicolinearity,we hadn't done the Data Transformation here because we are using non-parametric algorithms here, then we splitted and trained the Machine leaning model using certain algorithms like Logistic Regression,SVM(Support Vector Machine),Random Forest,Naive and XGBoost and also done Gridsearch cross validation in some of them and we got really got accurracy with the best of 92% for logistic regression and we have also checked the feature importance were ram is having the highest weightage on the final prediction."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rithun Rajendran M.K-https://github.com/Rithunrajendran/Mobile-price-range-prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the competitive mobile phone market companies want to understand sales data of mobile phones and factors which drive the prices. The objective is to find out some relation between features of a mobile phone(eg:- RAM, Internal Memory, etc) and its selling price. In this problem, we do not have to predict the actual price but a price range indicating how high the price is"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rzicaPvczi8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "Mobile_df=pd.read_csv(\"/content/drive/MyDrive/Capstone project 3/data_mobile_price_range.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "Mobile_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "Mobile_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "Mobile_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2000 rows and 21 columns.There seems to be no null values in it. It has integer and float as data types."
      ],
      "metadata": {
        "id": "Pd52QIeZCS9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(Mobile_df[Mobile_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(Mobile_df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(Mobile_df.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no null values in the Mobile Dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "Mobile_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "Mobile_df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Description**\n",
        "\n",
        "**Battery_power** - Total energy a battery can store in one time measured in mAh\n",
        "\n",
        "**Blue** - Has bluetooth or not\n",
        "\n",
        "**Clock_speed** - speed at which microprocessor executes instructions\n",
        "\n",
        "**Dual_sim** - Has dual sim support or not\n",
        "\n",
        "**Fc** - Front Camera mega pixels\n",
        "\n",
        "**Four_g** - Has 4G or not\n",
        "\n",
        "**Int_memory** - Internal Memory in Gigabytes\n",
        "\n",
        "**M_dep** - Mobile Depth in cm\n",
        "\n",
        "**Mobile_wt** - Weight of mobile phone\n",
        "\n",
        "**N_cores** - Number of cores of processor\n",
        "\n",
        "**Pc** - Primary Camera mega pixels\n",
        "\n",
        "**Px_height** - Pixel Resolution Height\n",
        "\n",
        "**Px_width** - Pixel Resolution Width\n",
        "\n",
        "**Ram** - Random Access Memory in Mega Bytes\n",
        "\n",
        "**Sc_h** - Screen Height of mobile in cm\n",
        "\n",
        "**Sc_w** - Screen Width of mobile in cm\n",
        "\n",
        "**Talk_time** - longest time that a single battery charge will last when you are\n",
        "\n",
        "**Three_g** - Has 3G or not\n",
        "\n",
        "**Touch_screen** - Has touch screen or not\n",
        "\n",
        "**Wifi** - Has wifi or not\n",
        "\n",
        "**Price_range**- This is the target variable with value of 0(low cost), 1(medium cost),2(high cost) and 3(very high cost)."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in Mobile_df.columns.tolist():\n",
        " print(\"No. of unique values in \",i,\"is\",Mobile_df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Create a copy of the current dataset and assigning to df\n",
        "df_mobile=Mobile_df.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimum value of px_height and sc_w cannot be zero so we will do some operations."
      ],
      "metadata": {
        "id": "uOrn-nXSiHHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total phones with sc_w = 0\n",
        "print(len(df_mobile[df_mobile.sc_w == 0]))\n",
        "# Total phones with px_height = 0\n",
        "print(len(df_mobile[df_mobile.px_height == 0]))"
      ],
      "metadata": {
        "id": "hFSKOhVHiNwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sc_W and px_height is zero ,assigning median values\n",
        "df_mobile['sc_w'].fillna(df_mobile['sc_w'].median(), inplace = True)\n",
        "df_mobile['px_height'].fillna(df_mobile['px_height'].median(), inplace = True)"
      ],
      "metadata": {
        "id": "_P8wG6iV2lAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we found pixel height and screen width to be zero in the dataset but these two variables can not be zero so i have replaced their zero values with their median value(not affected by outliers)."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1:Plot between price_range and Battery_power"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.barplot(x='price_range',y='battery_power',data=df_mobile,)\n",
        "plt.title('Plot between price_range and Battery_power ')"
      ],
      "metadata": {
        "id": "3f0nCHe151uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar graph helps to compare the different sets of data among different groups easily. It shows the relationship using two axes, in which the categories are on one axis and the discrete values are on the other axis. The graph shows the major changes in data over time."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As to gain high profit margin, company uses high mah battery into the mobile devices, as it is cleared from the above visualization that the customer can spend more money for buying phone with high battery capacity"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2:PLot of  price_range vs bluetooth and price_range vs Dual sim"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
        "crosstab_result_1=pd.crosstab(index=df_mobile['blue'],columns=df_mobile['price_range'])\n",
        "crosstab_result_1.plot.bar(ax=axs[0])\n",
        "crosstab_result_2=pd.crosstab(index=df_mobile['dual_sim'],columns=df_mobile['price_range'])\n",
        "crosstab_result_2.plot.bar(ax=axs[1])"
      ],
      "metadata": {
        "id": "jjfCjwt0J_2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot can also be used to plot the two categorical variables and result can be interpreted very easily."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the visualization, we can see that if bluetooth and dual sim is not present, then the price is low and if they are present, then the price is high."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3:Plot between price_range and ram"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(y=\"ram\", x=\"price_range\", data=df_mobile)\n",
        "plt.title('Plot between price_range and ram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A point plot represents an estimate of central tendency for a numeric variable by the position of the dot and provides some indication of the uncertainty around that estimate using error bars. Here we have used pointplot to find the relation between price_range and ram."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ram and mobile cost shows a linear relation i.e if ram of mobile increases then mobile get costly and otherwise if ram decreases, cost is less."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4:clock_speed vs price_range"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
        "sns.boxplot(data=df_mobile, x='price_range', y='clock_speed', ax=axs[0])\n",
        "sns.pointplot(y=\"clock_speed\", x=\"price_range\", data=df_mobile,ax=axs[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l_t-VkXzSwe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plots are used to show distributions of numeric data values, especially when you want to compare them between multiple groups. They are built to provide high-level information at a glance, offering general information about a group of data's symmetry, skew, variance, and outliers.\n",
        "\n",
        "A point plot represents an estimate of central tendency for a numeric variable by the position of the dot and provides some indication of the uncertainty around that estimate using error bars."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally,The clock speed determines how many instructions the processor can execute per second.The general rule is that higher clock speeds make for faster phones. You can often see this with more expensive smartphones.But from the graph,if the price of mobile is low, clock speed is high and if price is increased then clock speed seems to be decreased and another point if price is further increase,clock speed increase.So the general idea for clock speed is not much clear in the available data."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5:Checking if phone supports 3G and checking for 4G "
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage of phones which support 3g\n",
        "labels = [\"3G-supported\",'Not supported']\n",
        "values=df_mobile['three_g'].value_counts().values\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(values, labels=labels, autopct='%1.1f%%',shadow=True,startangle=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1lRfH7mU_Nl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage of phones which support 4g\n",
        "labels = [\"4G-supported\",'Not supported']\n",
        "values=df_mobile['four_g'].value_counts().values\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(values, labels=labels, autopct='%1.1f%%',shadow=True,startangle=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k-o0y7ZdAD6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Pie Chart is a circular statistical plot that can display only one series of data. The area of the chart is the total percentage of the given data."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the first pie graph we can say that 76.2% mobile phones support 3G and 23.8% doesnot support 3G and in the second graph its clear that 52.1% supports 4G and 48.9% doesnot support 4g."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 : Wifi vs Price Range"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mobile['wifi'].value_counts()"
      ],
      "metadata": {
        "id": "kiKtEyawYelx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mobile['wifi'].value_counts().plot.pie (autopct='%1.1f%%', shadow=True, labeldistance=None)\n",
        "plt.title('Wifi by value_count')\n",
        "plt.legend(['Support', 'Does not Support'], bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-f8ItPpi89St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Considering only phones with Wifi\n",
        "\n",
        "wifi_one = df_mobile[df_mobile['wifi']==1]"
      ],
      "metadata": {
        "id": "5xu3C-Ct-Iq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Barplot of wifi vs price_range\n",
        "fig,ax=plt.subplots(figsize=(10,5))\n",
        "sns.barplot(data=wifi_one,x='price_range',y='wifi', ax=ax)\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Wifi')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O9NkxcB09_Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check how many phones support Wifi and how many do not.\n",
        "\n",
        "Also, to observe the distribution of Phones that support Wifi in the price ranges."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of phones that have Wifi support and don't are almost equal. This tells us that almost half of the phones do not support wifi.\n",
        "\n",
        "The phones that support Wifi are equally distributed among all price ranges.\n",
        "Hence, we can claim that Wifi is not a determining factor in price range."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7:Megapixel vs Price_range"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the average  megapixel according to their price range.\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.set()\n",
        "df_mobile.groupby(\"price_range\")[\"pc\"].mean().plot( kind='bar', color=list('rbky'),)\n",
        "plt.ylabel(\"megapixel\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the average megapixel with price_range"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For price range 0,1.2,3 the average megapixel is around 9 to 10 megapixel."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8:Mobile_wt vs price_range"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "sns.set_style(\"darkgrid\")\n",
        "df_mobile.boxplot(by ='price_range', column =['mobile_wt'], grid = False,color='red')\n",
        "plt.ylabel(\"mobile Weight (Gram)\")\n",
        "\n",
        "sns.displot(data=df_mobile, x=\"mobile_wt\", hue=\"price_range\", kind=\"kde\")"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the weights of mobiles according to price_range"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this observation we can say that the costlier phone are lighter in weight."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 9 : Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(df_mobile.corr(),annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will be using correlation heatmap to check the colinearity between independent and dependent variable price_range."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAM has strong positive correlation with the Price_range. and we know that Mobiles with high RAM are very costly. Thus RAM increases price range also increase.\n",
        "\n",
        "Battery_power also has positive correlation with the price range.Generally mobiles having high prices comes with good battery power.\n",
        "\n",
        "Also px_height and px_width (Pixel Resolution Height and width) are positively correlated. Generally High price range mobiles have good resolutions.\n",
        "\n",
        "Four_g and Three_g are highly positvely correlated. Nowdays most of the smart mobiles has both type of options. This could be the reason that they are correlated.\n",
        "\n",
        "primary camera  and front camera  are positively correlated.\n",
        "\n",
        "sc_h and sc_w are positively correlated"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df_mobile, hue=\"price_range\")\n"
      ],
      "metadata": {
        "id": "YwLYTsSESmFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df_mobile.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no NULL values present in the dataset so no operation is required here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "#creating list of numerical  columns\n",
        "numerical_columns=['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']\n",
        "\n",
        "plt.figure(figsize=(17,10))\n",
        "for n,column in enumerate(numerical_columns):\n",
        "  plt.subplot(5, 4, n+1)\n",
        "  sns.boxplot(df_mobile[column])\n",
        "  plt.title(f'{column.title()}',weight='bold')\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are negligible amount of outliers."
      ],
      "metadata": {
        "id": "Y7ImSYXZVpXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "No outlier treatment was performed as there are not a considerable amount of outliers."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "categorical_columns=['dual_sim', 'blue', 'wifi', 'three_g', 'touch_screen',  'four_g']\n",
        "\n",
        "# Plotting Pie chart for our Categorical columns variables\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "count = 0\n",
        "\n",
        "# Loop to get the Pie chart of all categorical columns\n",
        "for feature in categorical_columns:\n",
        "    \n",
        "    # output formatting of the pie chart\n",
        "    explode = [0, 0.1]\n",
        "    \n",
        "    labels = df_mobile[feature].value_counts().index\n",
        "    sizes = df_mobile[feature].value_counts().values \n",
        "\n",
        "    # Deciding the proper postioning of the subplots in the output\n",
        "    plt.subplot(2,3,count+1)\n",
        "\n",
        "    # Pie Chart visualization code\n",
        "    plt.pie(sizes, labels=labels, explode = explode, shadow = True, startangle=90, autopct='%1.1f%%')\n",
        "    plt.title(f'Distribution of {categorical_columns[count]}', color = 'black',fontsize = 12)\n",
        "    count += 1\n",
        "     "
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 means it has the specification\n",
        "\n",
        "0 means it does not have the specification\n",
        "\n",
        "Every categorical feature shows a similar trend of almost equal class distribution except for the 3G which highlights this fact that most of the mobile phones nowadays contains atleast a 3G sim slot."
      ],
      "metadata": {
        "id": "lri9GdfnYNJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# multiplying px_height and px_width to get px_area\n",
        "df_mobile['px_area']=df_mobile['px_width']*df_mobile['px_height']  "
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping px_height and px_width\n",
        "df_mobile.drop('px_height',axis=1,inplace=True)\n",
        "df_mobile.drop('px_width',axis=1,inplace=True)     "
      ],
      "metadata": {
        "id": "eWdrDOSLh9z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplying columns sc_h and sc_w to get sc_area\n",
        "df_mobile['sc_area']=df_mobile['sc_w']*df_mobile['sc_h']"
      ],
      "metadata": {
        "id": "2M1wB_NkiJDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping sc_h and sc_w\n",
        "df_mobile.drop('sc_h',axis=1,inplace=True)\n",
        "df_mobile.drop('sc_w',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "XPZAm70UlZcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "X=df_mobile.drop('price_range',axis=1)\n",
        "#VIF dataframe\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "  \n",
        "#calculating VIF for each feature\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
        "                          for i in range(len(X.columns))]\n",
        "     \n"
      ],
      "metadata": {
        "id": "8fGsqM7VmEEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vif_data)"
      ],
      "metadata": {
        "id": "Nkpvh2JEm2hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the dependent variable and unnecessary variable\n",
        "X=df_mobile.drop(['price_range','mobile_wt'],axis=1) \n",
        "  \n",
        "#VIF dataframe\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "  \n",
        "#calculating VIF for each feature\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
        "                          for i in range(len(X.columns))]\n",
        "     "
      ],
      "metadata": {
        "id": "lZvx9tb7nJd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vif_data)"
      ],
      "metadata": {
        "id": "xaRsnmXZnZqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After dropping mobile_wt, the VIF values are all below 10."
      ],
      "metadata": {
        "id": "NQNK0gPRplpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used VIF( Variance inflation Factor) to decide the features to select. It tells us the strength of correlation among the independent variables. We have  dropped the column mobile_wt since it had a high VIF value. we also created the columns px_area and sc_area using the columns px_height, px_width, sc_h and sc_w."
      ],
      "metadata": {
        "id": "sLptRrasp0DR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "X=df_mobile.drop(['price_range','mobile_wt'],axis=1)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "id": "IkmLv5wQqo3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used VIF( Variance inflation Factor) to decide the features to select. It tells us the strength of correlation among the independent variables. We have  dropped the column mobile_wt since it had a high VIF value. we also created the columns px_area and sc_area using the columns px_height, px_width, sc_h and sc_w."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features  'battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g','int_memory', 'm_dep', 'n_cores', 'pc', 'ram', 'talk_time', 'three_g', 'touch_screen', 'wifi', 'px_area', 'sc_area are important ,we have removed the input variable whose VIF is above 10."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We think that the data transformation is not requird here as we the algorithm we are using are non-parametric algorithm.Non-parametric classification algorithms do not make any assumptions about the underlying distribution of the data, while parametric classification algorithms assume that the data follows a specific distribution."
      ],
      "metadata": {
        "id": "8601WxGYdza2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "#Using minmax scaler to scale the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "Scaled_X=scaler.transform(X)   "
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Scaled_X)"
      ],
      "metadata": {
        "id": "ZsQJq-K3gBcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Minmaxscalar to scale our data.The MinMaxscaler is a type of scaler that scales the minimum and maximum values to be 0 and 1 respectively, so all the variables have values between 0 to 1."
      ],
      "metadata": {
        "id": "Ostn1b7FfFmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "#import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "Y=df_mobile['price_range']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting shape of train and test\n",
        "print(\"X_train shape \", X_train.shape)\n",
        "print(\"Y_train shape \", Y_train.shape)\n",
        "print(\"X_test shape \",X_test.shape)\n",
        "print(\"Y_test shape \",Y_test.shape)"
      ],
      "metadata": {
        "id": "blSnL2wjivMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before, fitting any model it is a rule to split the dataset into a training and test set. This means some proportions of the data will go into training the model and some portion will be used to evaluate how our model is performing on any unseen data known as testing data. The proportions may vary from 60:40, 70:30, 75:25 depending on the person but usually it is 80:20."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "price_range_values=df_mobile['price_range'].value_counts()\n",
        "price_range_values"
      ],
      "metadata": {
        "id": "K1CU4fSGjV-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have equal number of obseravtions for each categoryso the dataset is not imbalanced Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "#Not needed"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target variable are balanced so no need to balance the dataset."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to calculate the metrics for evaluating the performance of models.\n",
        "from sklearn.metrics import accuracy_score,precision_score, recall_score,f1_score,confusion_matrix\n",
        "def evaluation_model(y_actual,y_pred):\n",
        "\n",
        "  '''\n",
        "  This function will calculate  diffrent metrics for evaluating \n",
        "  the perfomance of models\n",
        "  '''\n",
        "  list_of_scores=[]\n",
        "  #Accuracy \n",
        "  Accuracy =  accuracy_score(y_actual,y_pred)\n",
        "  print(f'Accuracy : {Accuracy}')\n",
        "    \n",
        "  #Recall\n",
        "  Recall  = recall_score(y_actual,y_pred,average='weighted')\n",
        "  print(f\"Recall : {Recall}\")\n",
        "\n",
        "  #precision\n",
        "  Precision = precision_score(y_actual,y_pred,average='weighted')\n",
        "  print(f\"Precision : {Precision}\")\n",
        " \n",
        "  #f1 score\n",
        "  F1 = f1_score(y_actual,y_pred,average='weighted')\n",
        "  print(f\"F1 : {F1}\")"
      ],
      "metadata": {
        "id": "TR2qqqVG0CMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function for understanding the confusion matrix.\n",
        "\n",
        "def confuse_matrix(actual, predicted):\n",
        "  labels = ['0','1','2','3']\n",
        "\n",
        "  # Confusion matrix\n",
        "  cm = confusion_matrix(actual, predicted)\n",
        "  print(cm)\n",
        "\n",
        "  ax = plt.subplot()\n",
        "\n",
        "  # Creating the heatmap\n",
        "  sns.heatmap(cm, annot=True, ax=ax)\n",
        "\n",
        "  ax.set_title('Confusion Matrix')\n",
        "  ax.set_xlabel('Predicted labels')\n",
        "  ax.set_ylabel('Actual labels')\n",
        "  \n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)\n",
        "  \n",
        "     "
      ],
      "metadata": {
        "id": "2tavyqiN0kp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 : Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# build a logistic regression model\n",
        "log_reg = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "log_reg.fit(X_train, Y_train)\n",
        "\n",
        "# transforming the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Fit the Algorithm\n",
        "log_reg.fit(X_train, Y_train)\n",
        "\n",
        "# Predict on the model\n",
        "log_reg_pred_train = log_reg.predict(X_train)   # Prediction for train dataset\n",
        "log_reg_pred_test = log_reg.predict(X_test)     # Prediction for test dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,log_reg_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,log_reg_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,log_reg_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,log_reg_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 : SVM(Support Vector Machine)"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM implementation\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM = SVC(C=10,random_state=50)\n",
        "\n",
        "# Fitting the Alogrithm\n",
        "SVM.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions of Training and Testing Dasets\n",
        "\n",
        "SVM_pred_train = SVM.predict(X_train)   # Prediction for train dataset\n",
        "SVM_pred_test = SVM.predict(X_test)     # Prediction for test dataset\n"
      ],
      "metadata": {
        "id": "J45iXn1cuUNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,SVM_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,SVM_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,SVM_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,SVM_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cu6gXTAl_tlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., RandomSearch CV)\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Selecting Hyperparameters\n",
        "params_dict = {'C': [0.01,0.1,1,10,100],\n",
        "              'gamma': [1,0.1,0.01,0.001],\n",
        "              'kernel': ['rbf','poly','sigmoid']}\n",
        "\n",
        "# Using Randomized Search CV\n",
        "SVM_model = RandomizedSearchCV(estimator = SVM,\n",
        "                       param_distributions= params_dict,\n",
        "                       cv = 5, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Fitting the Alogrithm\n",
        "SVM_model.fit(X_train,Y_train)\n",
        "\n",
        "# Getting the best Estimator\n",
        "print(SVM_model.best_estimator_)    \n",
        "print(\"\\n\")\n",
        "SVM_optimal = SVM_model.best_estimator_\n",
        "\n",
        "\n",
        "# Predictions of Training and Testing Dasets\n",
        "\n",
        "SVM_pred_train = SVM_optimal.predict(X_train)   # Prediction for train dataset\n",
        "SVM_pred_test = SVM_optimal.predict(X_test)     # Prediction for test dataset\n",
        "     "
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomizedSearchCV randomly passes the set of hyperparameters and calculate the score and gives the best set of hyperparameters which gives the best score as an output.It tries random combinations of a range of values. To optimise with random search, the function is evaluated at some number of random configurations in the parameter space."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,SVM_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,SVM_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,SVM_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,SVM_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i8L41VDqCbUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Training data we found the accuracy of 91%,Recall of 91%,Precision of 91% and F1 of 91% when compared to what we got previously(before Hyperparameter tuning) our model is overfitting as the accuracy,recall,precision,F1 all are giving 100%\n",
        "\n",
        "For Testing data we found the accuracy of 92%,Recall of 92%,Precision of 92% and F1 of 92% which has significantly improved to what we got previously (before Hyperparameter tuning) we got  accuracy of 87%,recall of 87%,precision of 88% and F1 of 87%."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 : Random Forest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest implementation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RD_forest = RandomForestClassifier()\n",
        "\n",
        "# Fitting the Alogrithm\n",
        "RD_forest.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions of Training and Testing Dasets\n",
        "\n",
        "RF_for_pred_train = RD_forest.predict(X_train)   # Prediction for train dataset\n",
        "RF_for_pred_test = RD_forest.predict(X_test)     # Prediction for test dataset\n",
        "     "
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,RF_for_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,RF_for_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,RF_for_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,RF_for_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OrpvM-zIFWOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., RandomSearch CV)\n",
        "\n",
        "# Importing GridSearchCV from sklearn\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Selecting Hyperparameters\n",
        "params_dict = {\n",
        "              'max_depth': [5,6,7,8,9,10],\n",
        "              'min_samples_leaf': [1,2,3,4,5],\n",
        "              'min_samples_split': [5,10,15],\n",
        "              'n_estimators': [100,200,300]\n",
        "              }\n",
        "\n",
        "# Using Randomized Search CV\n",
        "RF_model = RandomizedSearchCV(estimator = RD_forest,\n",
        "                       param_distributions= params_dict,\n",
        "                       cv = 5, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Fitting the Alogrithm\n",
        "RF_model.fit(X_train,Y_train)\n",
        "\n",
        "# Getting the best Estimator\n",
        "print(RF_model.best_estimator_)    \n",
        "print(\"\\n\")\n",
        "RD_Forest_optimal = RF_model.best_estimator_\n",
        "\n",
        "\n",
        "# Predictions of Training and Testing Dasets\n",
        "\n",
        "RD_Forest_pred_train = RD_Forest_optimal.predict(X_train)   # Prediction for train dataset\n",
        "RD_Forest_pred_test = RD_Forest_optimal.predict(X_test)     # Prediction for test dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomizedSearchCV randomly passes the set of hyperparameters and calculate the score and gives the best set of hyperparameters which gives the best score as an output.It tries random combinations of a range of values. To optimise with random search, the function is evaluated at some number of random configurations in the parameter space."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,RD_Forest_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,RD_Forest_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,RD_Forest_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,RD_Forest_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Pt5v-JrLgL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For Training data we found the accuracy of 98%,Recall of 98%,Precision of 98% and F1 of 98% when compared to what we got previously(before Hyperparameter tuning) our model is almost similar  as the accuracy,recall,precision,F1 all are giving 100%\n",
        "\n",
        "For Testing data we found the accuracy of 86%,Recall of 86%,Precision of 86% and F1 of 86% which is also similar to what we got previously (before Hyperparameter tuning) we got accuracy of 87%,recall of 87%,precision of 87% and F1 of 87%.\n",
        "\n"
      ],
      "metadata": {
        "id": "X_nskTC3wU8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 4 : XGBoost"
      ],
      "metadata": {
        "id": "yr4ogmVgxx24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost implementation\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "XGB = XGBClassifier()\n",
        "\n",
        "# Fitting the Alogrithm\n",
        "XGB.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions of Training and Testing Dasets\n",
        "\n",
        "XGB_pred_train = XGB.predict(X_train)   # Prediction for train dataset\n",
        "XGB_pred_test = XGB.predict(X_test)     # Prediction for test dataset"
      ],
      "metadata": {
        "id": "RO-45LX8yCYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "K-U63I8O1PLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,XGB_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,XGB_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,XGB_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,XGB_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TtJT-eFp2Fnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "2jxnDK5A29pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation with hyperparameter optimization techniques (i.e., RandomSearch CV)\n",
        "# Selecting Hyperparameters\n",
        "params_dict = {\n",
        "              'max_depth': [5,6,7,8,9,10],\n",
        "              'n_estimators': [100,200,300],\n",
        "              'learning_rate': [0.01,0.05,0.1,0.5]\n",
        "              }\n",
        "\n",
        "# Using Randomized Search CV\n",
        "XGB_model = RandomizedSearchCV(estimator = XGB,\n",
        "                       param_distributions= params_dict,\n",
        "                       cv = 5, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Fitting the Alogrithm\n",
        "XGB_model.fit(X_train,Y_train)\n",
        "\n",
        "# Getting the best Estimator\n",
        "print(XGB_model.best_estimator_)    \n",
        "print(\"\\n\")\n",
        "XGB_optimal = XGB_model.best_estimator_\n",
        "\n",
        "\n",
        "# Predictions of Training and Testing Dasets\n",
        "\n",
        "XGB_pred_train = XGB_optimal.predict(X_train)   # Prediction for train dataset\n",
        "XGB_pred_test = XGB_optimal.predict(X_test)     # Prediction for test dataset\n",
        "     "
      ],
      "metadata": {
        "id": "OaLvkI8v2eBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "xZ3OFuRT5KAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomizedSearchCV randomly passes the set of hyperparameters and calculate the score and gives the best set of hyperparameters which gives the best score as an output.It tries random combinations of a range of values. To optimise with random search, the function is evaluated at some number of random configurations in the parameter space."
      ],
      "metadata": {
        "id": "HmVz6n8I5TmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "fcSk5G885bJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,XGB_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,XGB_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,XGB_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,XGB_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F4gwfUQF4PvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Training data we found the accuracy of 100%,Recall of 100%,Precision of 100% and F1 of 100% when compared to what we got previously(before Hyperparameter tuning) our model is  similar as the accuracy,recall,precision,F1 all are giving 100%\n",
        "\n",
        "For Testing data we found the accuracy of 90%,Recall of 90%,Precision of 90% and F1 of 90% which is also similar to what we got previously (before Hyperparameter tuning) we got accuracy of 91%,recall of 91%,precision of 91% and F1 of 91%."
      ],
      "metadata": {
        "id": "kBs0NJ3lBdnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 5 : Naive Bayes"
      ],
      "metadata": {
        "id": "XDcqx0o3DYcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes implementation\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "NB = GaussianNB()\n",
        "\n",
        "# Fitting the Algorithm\n",
        "NB.fit(X_train, Y_train)\n",
        "\n",
        "# Predictions of Training and Testing Dasets\n",
        "\n",
        "NB_pred_train = NB.predict(X_train)   # Prediction for train dataset\n",
        "NB_pred_test = NB.predict(X_test)     # Prediction for test dataset"
      ],
      "metadata": {
        "id": "xdX5M3MsDNU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "iVm-aUYlDuZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Evaluation metrices for the Training Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_train,NB_pred_train)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Evaluation metrices for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling evaluation_model function\n",
        "evaluation_model(Y_test,NB_pred_test)\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Training Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_train,NB_pred_train)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print('\\n')\n",
        "print(\"Confusion metrix for the Testing Data\")\n",
        "print('\\n')\n",
        "# calling confusion metrics function\n",
        "confuse_matrix(Y_test,NB_pred_test)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zz6wHdEKDzhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing matrix of  every models"
      ],
      "metadata": {
        "id": "Wf7JPPmrEZzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy score should be used over precision,recall and F1 score when the classes in the dataset are balanced.Accuracy provides a simple and intuitive measure of the model's overall performance in correctly classifying instances. The higher the accuracy score, the better the model is at predicting the correct class."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing different  metrics in order to make dataframe and compare them\n",
        "models = [\"Logistic_regression\",\"SVM\",\"Random Forest\",\"XGboost\",\"Naive_bayes\",]\n",
        "Accuracy = [0.92,0.89,0.88,0.90,0.78]\n",
        "Recall = [0.92,0.89,0.88,0.90,0.78]\n",
        "Precision = [0.92,0.89,0.88,0.90,0.79] \n",
        "F1_Score= [0.92,0.89,0.88,0.90,0.78]\n",
        "\n",
        "# Create dataframe from the lists\n",
        "data = {'Models': models,\n",
        "        'Accuracy':Accuracy,\n",
        "        'Recall':Recall,\n",
        "        'Precision':Precision,\n",
        "        'F1_Score':F1_Score,\n",
        "        }\n",
        "df_metrics = pd.DataFrame(data)\n",
        "\n",
        "# Printing dataframe\n",
        "df_metrics\n",
        "     \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PJiwmokMEvUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among all the 5 model we have trained so far, the highest recall, F-1 score,Precision and accuracy we are getting with Logistic Regression. So , we are considering Logistic Regression as our final optimal model."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since, Logistic Regression is the best proven model for us, so we will do a feature importance with the functionality of .coef_."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the feature importance\n",
        "importance = log_reg.coef_[0]\n",
        "\n",
        "# Create a dictionary of feature names and their importance scores\n",
        "feature_importance = dict(zip(X.columns, importance))\n",
        "\n",
        "# Sort the features by their importance scores (in descending order)\n",
        "sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Create a bar plot of feature importance\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[x[0] for x in sorted_features], y=[x[1] for x in sorted_features])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Importance Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WksbZZ7VHhW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here from the bargraph we can clearly see that  for our model RAM is adding the highest weightage followed by battery_powerto our final prediction i.e, the price_range."
      ],
      "metadata": {
        "id": "siqBu-fTJuEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset-data_mobile_price_range.csv\n",
        "\n",
        "Shape of the Dataset=(2000,21)\n",
        "\n",
        "From EDA we can see that, there are mobile phones in 4 price ranges  with value of 0(low cost), 1(medium cost), 2(high cost) and 3(very high cost).\n",
        "\n",
        ". As to gain high profit margin, company uses high mah battery into the mobile devices, as the customers spend more money for buying phone with high battery capacity.\n",
        "\n",
        ". If bluetooth and dual sim is not present, then the price is low and if they are present, then the price is high.\n",
        "\n",
        ". Ram and mobile cost shows a linear relation i.e if ram of mobile increases then mobile get costly and otherwise if ram decreases, cost is less.\n",
        "\n",
        ". Generally,The clock speed determines how many instructions the processor can execute per second.The general rule is that higher clock speeds make for faster phones. You can often see this with more expensive smartphones.But from the graph,if the price of mobile is low, clock speed is high and if price is increased then clock speed seems to be decreased and another point if price is further increase,clock speed increase.So the general idea for clock speed is not much clear in the available data.\n",
        "\n",
        ". 76.2% mobile phones support 3G and 23.8% doesnot support 3G and in the second graph its clear that 52.1% supports 4G and 48.9% doesnot support 4g.\n",
        "\n",
        ". The number of phones that have Wifi support and don't are almost equal. This tells us that almost half of the phones do not support wifi.\n",
        "\n",
        "The phones that support Wifi are equally distributed among all price ranges. Hence, we can claim that Wifi is not a determining factor in price range.\n",
        "\n",
        ". For price range 0,1.2,3 the average megapixel is around 9 to 10 megapixel.\n",
        "\n",
        ". The costlier phone are lighter in weight.\n",
        "\n",
        "Conclusion from model training:\n",
        "\n",
        "we have implemented 5 classification models and achieved a fairly good result for all the algorithms.We have Done Randomsearch cross validation to rectify the misclassifed data.\n",
        "\n",
        ". Logistic Regression\n",
        "\n",
        ". SVM(Support Vector Machine)\n",
        "\n",
        ". Random Forest\n",
        "\n",
        ". Naive Bayes\n",
        "\n",
        ". XGBoost\n",
        "\n",
        ". From the 5 Classification models Logistic regression the highest accuracy of 92% and Naive with lowest of 78%,so Logistic regression is the optimal model here.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}